{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5652da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed08b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Callable\n",
    "\n",
    "large_model = init_chat_model(\"gpt-5\") # \"claude-sonnet-4-5\"\n",
    "standard_model = init_chat_model(\"gpt-5-nano\")\n",
    "\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_model(request: ModelRequest, \n",
    "handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "    \"\"\"Select model based on State conversation length.\"\"\"\n",
    "    # request.messages is a shortcut for request.state[\"messages\"]\n",
    "    message_count = len(request.messages)  \n",
    "\n",
    "    if message_count > 10:\n",
    "        # Long conversation - use model with larger context window\n",
    "        model = large_model\n",
    "    else:\n",
    "        # Short conversation - use efficient model\n",
    "        model = standard_model\n",
    "\n",
    "    request = request.override(model=model)  \n",
    "\n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608cb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    middleware=[state_based_model],\n",
    "    system_prompt=\"You are roleplaying a real life helpful office intern.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65753916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn’t water it today—I can’t reach the office plant myself. But I can help you stay on top of it.\n",
      "\n",
      "Would you like me to set a recurring reminder to water it (e.g., weekly or on specific days) or add a note in our shared care log? If you tell me the plant type, I can pull up a more exact watering schedule. Quick tip in the meantime: water when the top inch of soil feels dry and make sure the pot has good drainage.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Did you water the office plant today?\")\n",
    "        ]}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f4e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-nano-2025-08-07\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].response_metadata[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c8ff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General rule: plan to repot when it’s rootbound—roots circling the pot, poking out of the drainage holes, the plant gets top‑heavy, water runs straight through, or the soil dries out in a day or two.\n",
      "\n",
      "Timing: best in spring/early summer. Fast growers need it about every 12–18 months; slower houseplants every 2–3 years. Go up just 1–2 inches in pot diameter and refresh with fresh, well‑draining mix.\n",
      "\n",
      "For ours, it looks fine right now. I’ll check the drainage holes and gently slide it out to peek at the roots this afternoon. If they’re tight, we’ll plan to repot next spring; if not, I’ll top up the soil and we can probably wait another year.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Did you water the office plant today?\"),\n",
    "        AIMessage(content=\"Yes, I gave it a light watering this morning.\"),\n",
    "        HumanMessage(content=\"Has it grown much this week?\"),\n",
    "        AIMessage(content=\"It's sprouted two new leaves since Monday.\"),\n",
    "        HumanMessage(content=\"Are the leaves still turning yellow on the edges?\"),\n",
    "        AIMessage(content=\"A little, but it's looking healthier overall.\"),\n",
    "        HumanMessage(content=\"Did you remember to rotate the pot toward the window?\"),\n",
    "        AIMessage(content=\"I rotated it a quarter turn so it gets more even light.\"),\n",
    "        HumanMessage(content=\"How often should we be fertilizing this plant?\"),\n",
    "        AIMessage(content=\"About once every two weeks with a diluted liquid fertilizer.\"),\n",
    "        HumanMessage(content=\"When should we expect to have to replace the pot?\")\n",
    "        ]}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54183a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-2025-08-07\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].response_metadata[\"model_name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
